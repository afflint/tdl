{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43e0fe86",
   "metadata": {},
   "source": [
    "#### Tecnologie dei dati e del linguaggio\n",
    "# Significato e contesto\n",
    "## *You Shall Know a Word by the Company It Keeps*\n",
    "### Prof. Alfio Ferrara\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22a0ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab2606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aafcc4f",
   "metadata": {},
   "source": [
    "## Dataset e nuovo obiettivo\n",
    "Come esempio, useremo le ricette prese dal dataset [**Food.com Recipes with Search Terms and Tags**](https://www.kaggle.com/datasets/shuyangli94/foodcom-recipes-with-search-terms-and-tags).\n",
    "\n",
    "Contrariamente al caso della classificazione, cercheremo in questo caso di predire, dato un ingrediente, quali altri ingredienti appaiono nel contesto dell'ingrediente dato.\n",
    "\n",
    "## Contesto\n",
    "Possiamo definire il contesto in due modi:\n",
    "1. **Skip-gram**: ogni ingrediente ha come contesto gli ingredienti che compaiono nella stessa ricetta (eventualmente entro una certa finestra)\n",
    "2. **Continuous Bag of Words (CBOW)**: a partire dagli ingredienti di una ricetta (entro una finestra), vogliamo predire l'ingrediente centrale\n",
    "\n",
    "#### Esempio:\n",
    "\n",
    "Supponiamo di avere una finestra di contesto pari a 2, quindi, per ogni ingrediente, osserviamo i 2 ingredienti prima e dopo.\n",
    "\n",
    "![](./imgs/context.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444c4ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e8921",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pymongo.MongoClient()['cousine']\n",
    "recipes = db['foodcom']\n",
    "label_field = 'category'\n",
    "data = []\n",
    "labels = ['italian', 'indian', 'southern', 'mexican', 'chinese', 'greek', 'thai']\n",
    "\n",
    "q = {'search_terms': {'$in': labels}}\n",
    "for recipe in recipes.find(q):\n",
    "    data.append({\n",
    "        'ingredients': recipe['ingredients'],\n",
    "        label_field: [x for x in recipe['search_terms'] if x in labels][0]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1ed03a",
   "metadata": {},
   "source": [
    "### Creazione del dataset di training\n",
    "\n",
    "Obiettivo: predire un ingrediente dato il contesto (**CBOW**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e6f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import nltk \n",
    "import nlp.wordbags as wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45f3d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pymongo.MongoClient()['cousine']\n",
    "recipes = db['foodcom']\n",
    "corpus = []\n",
    "q = {}\n",
    "for recipe in recipes.find(q).limit(15000):\n",
    "    corpus.append(recipe['ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caafaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = wb.Bow(corpus=corpus, min_occurrences=10)\n",
    "dataloader, inputs, targets = bow.one_hot_cbow_dataloader(window=4, batch=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb9bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in dataloader:\n",
    "    print(f\"Inputs: {x}\")\n",
    "    print(f\"Target: {y}\")\n",
    "    print()\n",
    "    print(f\"Inputs shape: {x.shape}\")\n",
    "    print(f\"Target shape: {y.shape}\")\n",
    "    for j, row in enumerate(x):\n",
    "        input_ingredient = [bow.idx2word[i] for i, k in enumerate(row) if k > 0]\n",
    "        target_ingredients = [bow.idx2word[i] for i, k in enumerate(y[j]) if k > 0]\n",
    "        print(f\"\\nIngrediente di input: {input_ingredient}\")\n",
    "        print(f\"Ingredienti target: {target_ingredients}\\n\")\n",
    "    break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12938068",
   "metadata": {},
   "source": [
    "### Rete neurale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be56bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d292ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6563211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleNet(input_size=len(bow.idx2word), output_size=len(bow.idx2word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83da215b",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6fbc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb8de55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(document_tensor, label_tensor, criterion, learning_rate):\n",
    "    net.zero_grad()\n",
    "    output = net(document_tensor)\n",
    "    loss = criterion(output, label_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    for p in net.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249466be",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [(doc, lab) for doc, lab in dataloader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949097d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 30_000\n",
    "print_every = 2000\n",
    "plot_every = 200\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01\n",
    "\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "epochs = list(range(1, n_iters + 1))\n",
    "for it in tqdm(epochs):\n",
    "    document_tensor, label_tensor = batches[np.random.randint(0, len(batches) - 1)]\n",
    "    output, loss = train(document_tensor, label_tensor, criterion, learning_rate)\n",
    "    current_loss += loss\n",
    "\n",
    "    if it % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d25dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(all_losses, 'g')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95300ca9",
   "metadata": {},
   "source": [
    "## Predittore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6490fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(ingredients: list):\n",
    "    input_vector = [np.zeros(len(bow.vocabulary), dtype=np.float32)]\n",
    "    for i in ingredients:\n",
    "        try:\n",
    "            input_vector[0][bow.word2idx[i]] = 1\n",
    "        except KeyError:\n",
    "            pass \n",
    "    return torch.tensor(input_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d4466",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cd3b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = vectorize(['zucchini', 'spaghetti', 'parmesan cheese'])\n",
    "with torch.no_grad():\n",
    "    y_pred = net(ingredients)\n",
    "    y_pred = F.softmax(y_pred, dim=1)\n",
    "pd.Series(y_pred[0], index=bow.vocabulary).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7010e31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top20 = pd.Series(y_pred[0], index=bow.vocabulary).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcab5f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(top20.values, 'g')\n",
    "ax.set_ylim((0, 0.02))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d04b6a6",
   "metadata": {},
   "source": [
    "### Domanda difficile: perchè la rete non impara nulla e attribuisce a tutti gli ingredienti una probabilità così alta?\n",
    "\n",
    "Partiamo dall'idea che la rete calcola:\n",
    "\n",
    "$$\n",
    "\\hat{y} = softmax(\\theta.T x)\n",
    "$$\n",
    "\n",
    "ma dato che $x$ è un vettore one-hot, il prodotto $\\theta.T$ non fa altro che selezionare una colonna della matrice dei parametri e aggiornare solo quella. In pratica calcoliamo solo:\n",
    "\n",
    "$$\n",
    "\\hat{y} = softmax(\\theta.T x_i)\n",
    "$$\n",
    "\n",
    "QUindi tutti i vettori di input si appiattiscono in modo simile, e softmax dà sempre una distribuzione simile. Tutte le probabilità si avvicinano e nessuna parola viene predetta correttamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03052352",
   "metadata": {},
   "source": [
    "## Alcune considerazioni sui parametri della rete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a203f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([x for x in net.named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b5f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {name: param.detach().numpy() for name, param in net.named_parameters()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fcc7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['fc.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81ca8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_vectors = pd.DataFrame(params['fc.weight'].T, index=bow.vocabulary, columns=bow.vocabulary)\n",
    "feature_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f340c2",
   "metadata": {},
   "source": [
    "Ora, proviamo a calcolare la similarità tra ingredienti utilizzando questi vettori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60310bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb8d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = cosine_similarity(feature_vectors, feature_vectors)\n",
    "S = pd.DataFrame(sigma, index=bow.vocabulary, columns=bow.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250a2c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "S.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175c89d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'soy sauce'\n",
    "S.loc[query].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733cca00",
   "metadata": {},
   "source": [
    "## Introduzione di un layer intermedio (hidden layer)\n",
    "![](./imgs/hidden.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f231799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        super(HiddenNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc3bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = HiddenNet(input_size=len(bow.idx2word), output_size=len(bow.idx2word), hidden_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8821a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 50_000\n",
    "print_every = 2000\n",
    "plot_every = 200\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.1\n",
    "\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "epochs = list(range(1, n_iters + 1))\n",
    "for it in tqdm(epochs):\n",
    "    document_tensor, label_tensor = batches[np.random.randint(0, len(batches) - 1)]\n",
    "    output, loss = train(document_tensor, label_tensor, criterion, learning_rate)\n",
    "    current_loss += loss\n",
    "\n",
    "    if it % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2e4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(all_losses, 'g')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d1cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = vectorize(['zucchini', 'spaghetti', 'parmesan cheese'])\n",
    "with torch.no_grad():\n",
    "    y_pred = net(ingredients)\n",
    "    y_pred = F.softmax(y_pred, dim=1)\n",
    "pd.Series(y_pred[0], index=bow.vocabulary).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06757fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top20 = pd.Series(y_pred[0], index=bow.vocabulary).sort_values(ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(top20.values, 'g')\n",
    "ax.set_ylim((0, 0.02))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbe49fb",
   "metadata": {},
   "source": [
    "## Prendiamo i primi valori per ottenere un embedding di dimensione pari all'hidden layer per ogni ingrediente\n",
    "\n",
    "### Domanda: è chiaro perchè la matrice ha questa dimensione?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9800a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {name: param.detach().numpy() for name, param in net.named_parameters()}\n",
    "feature_vectors = pd.DataFrame(params['fc1.weight'].T, index=bow.vocabulary)\n",
    "feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aa1f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = cosine_similarity(feature_vectors, feature_vectors)\n",
    "S = pd.DataFrame(sigma, index=bow.vocabulary, columns=bow.vocabulary)\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ab3f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'soy sauce'\n",
    "S.loc[query].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050eef26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e106683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
